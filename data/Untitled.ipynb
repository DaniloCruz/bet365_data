{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pickle.load(open('data.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data) 14051\n",
      "len(result.groupby('name')) 1005\n"
     ]
    }
   ],
   "source": [
    "print(\"len(data) %d\"%len(data))\n",
    "print(\"len(result.groupby('name')) %d\"%len(data.groupby('name')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=[]\n",
    "for i,row in data.iterrows():\n",
    "    sample={}\n",
    "    name,date,minute=row[['name','date','minute']]\n",
    "    row=row['data']\n",
    "    sample['name']=name\n",
    "    sample['date']=date\n",
    "    sample['league']=row['league']\n",
    "    sample['minute']=row['minute']\n",
    "    #for c in ['name','corner','yellow','red','throw','freekick','goal']:\n",
    "    for c in ['name','corner','yellow','red','goal']:\n",
    "        if len(row[c])!=2:\n",
    "            sample[c+'_h'],sample[c+'_a']=np.NaN, np.NaN\n",
    "        else:\n",
    "            sample[c+'_h'],sample[c+'_a']=row[c][0],row[c][1]\n",
    "    if 'titles' in row:\n",
    "        for i,c in enumerate(row['titles']):\n",
    "            sample[c+'_h'],sample[c+'_a']=row['stats'][0,i],row['stats'][1,i]\n",
    "    #for c in ['Fulltime Result','Double Chance','Half Time Result','1st Goal']:\n",
    "    for c in ['Fulltime Result','Double Chance']:\n",
    "        sample[c+'_h']=row['odds'][c][0] if c in row['odds'].keys() else np.NaN\n",
    "        sample[c+'_d']=row['odds'][c][1] if c in row['odds'].keys() else np.NaN\n",
    "        sample[c+'_a']=row['odds'][c][2] if c in row['odds'].keys() else np.NaN\n",
    "    samples.append(pd.Series(sample))\n",
    "samples=pd.concat(samples,axis=1,sort=False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(samples) 14049\n"
     ]
    }
   ],
   "source": [
    "#clean\n",
    "samples=samples.dropna(subset=['goal_h','goal_a'])\n",
    "print('len(samples) %d'%len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_concat.shape 6955\n",
      "len(samples_gp) 667\n"
     ]
    }
   ],
   "source": [
    "final_minute=85\n",
    "\n",
    "def add_label(group):\n",
    "    if group.iloc[-1]['goal_h']>group.iloc[-1]['goal_a']: label=1\n",
    "    elif group.iloc[-1]['goal_h']==group.iloc[-1]['goal_a']: label=0\n",
    "    elif group.iloc[-1]['goal_h']<group.iloc[-1]['goal_a']: label=-1\n",
    "    group['label']=label\n",
    "    return group\n",
    "\n",
    "def add_orig_odds(group):\n",
    "    if group.iloc[0]['minute']!=0:\n",
    "        group['Orig Fulltime Result_h']=np.NaN\n",
    "        group['Orig Fulltime Result_d']=np.NaN\n",
    "        group['Orig Fulltime Result_a']=np.NaN\n",
    "    else:\n",
    "        group['Orig Fulltime Result_h']=group.iloc[0]['Fulltime Result_h']\n",
    "        group['Orig Fulltime Result_d']=group.iloc[0]['Fulltime Result_d']\n",
    "        group['Orig Fulltime Result_a']=group.iloc[0]['Fulltime Result_a']\n",
    "    return group\n",
    "\n",
    "def filter_minute(group):\n",
    "    group=group.sort_values('minute')\n",
    "    result=[]\n",
    "    for i,row in group.iterrows():\n",
    "        if not result:\n",
    "            result.append(row)\n",
    "        elif row['minute']>=result[-1]['minute']+5:\n",
    "            result.append(row)\n",
    "    result=pd.concat(result,axis=1,sort=False).T\n",
    "    return result\n",
    "\n",
    "def process_group(group,name=None,date=None):\n",
    "    group=group.sort_values('minute')\n",
    "    if group.iloc[-1]['minute']<final_minute:\n",
    "        #print(name)\n",
    "        return None\n",
    "    group=add_label(group)\n",
    "    group=add_orig_odds(group)\n",
    "    group=filter_minute(group)\n",
    "    return group\n",
    "\n",
    "groups=samples.groupby(['name','date'])\n",
    "result=[process_group(group,name,date) for (name,date), group in groups]\n",
    "samples_gp=[x for x in result if x is not None ]\n",
    "samples_concat=pd.concat(result,sort=False)\n",
    "print('samples_concat.shape %d'%samples_concat.shape[0])\n",
    "print(\"len(samples_gp) %d\"%len(samples_gp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean again\n",
    "gp_cleaned=[]\n",
    "for group in samples_gp:\n",
    "    #group=group.dropna(subset=['Fulltime Result_h', 'Fulltime Result_d','Fulltime Result_a'])\n",
    "    #group=group.dropna(subset=['Orig Fulltime Result_%s'%i for i in ['h','d','a']])\n",
    "    #group=group.dropna(subset=['Possession %_h','Possession %_a'])\n",
    "    group=group.drop(['Double Chance_h','Double Chance_d','Double Chance_a'],axis=1)\n",
    "    group=group.dropna()\n",
    "    gp_cleaned.append(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "s=pd.concat(gp_cleaned,sort=False)\n",
    "print('len %d'%len(s))\n",
    "print('s.groupby len %d'%len(s.groupby(['name','date'])))\n",
    "s.isna().sum()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random sample from samples_gp\n",
    "num_each_group=5\n",
    "gp_final=[]\n",
    "for group in gp_cleaned:\n",
    "    group=group[(group['minute']<80)&(group['minute']>30)]\n",
    "    if group.empty:\n",
    "        continue\n",
    "    idx=[random.randrange(0,len(group)) for _ in range(num_each_group)]\n",
    "    group=group.iloc[idx].set_index(['name','date','league','name_h','name_a'])\n",
    "    gp_final.append(group)\n",
    "print('len(gp_final) %d'%len(gp_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_train:[0.7578544061302682, 0.7417624521072796, 0.7371647509578544, 0.7762452107279694, 0.7440613026819923, 0.7563218390804598, 0.7478927203065134, 0.7310344827586207, 0.7440613026819923, 0.7432950191570882, 0.7386973180076628, 0.7318007662835249, 0.7379310344827587, 0.7371647509578544, 0.7310344827586207, 0.7412213740458016, 0.7412213740458016, 0.7633587786259542, 0.7351145038167939, 0.7633587786259542]\n",
      "mean:0.745030\n",
      "acc_test:[0.4857142857142857, 0.5714285714285714, 0.7428571428571429, 0.5571428571428572, 0.7571428571428571, 0.5714285714285714, 0.7428571428571429, 0.7, 0.5428571428571428, 0.7142857142857143, 0.6571428571428571, 0.7428571428571429, 0.6714285714285714, 0.8571428571428571, 0.6142857142857143, 0.7230769230769231, 0.8, 0.4307692307692308, 0.5692307692307692, 0.5538461538461539]\n",
      "mean:0.650275\n",
      "fullmatch:[0.7901428571428571, 0.822857142857143, 0.4009142857142856, 1.0179999999999998, 0.6338484848484848, 1.0736857142857141, 0.24840000000000004, 0.5551142857142858, 1.1067941176470588, 1.655090909090909, 2.8925, 0.9566285714285716, 0.9772941176470586, 1.0468571428571432, 1.2060857142857142, 0.42509677419354835, 1.1282187499999998, 0.1478125, 1.29646875, 2.5333548387096774]\n",
      "mean:1.045758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "kfold=KFold(20)\n",
    "acc_train,acc_test,fullmatch=[],[],[]\n",
    "for idx_train, idx_test in kfold.split(gp_final):\n",
    "    gp_train=[gp_final[idx] for idx in idx_train]\n",
    "    gp_test=[gp_final[idx] for idx in idx_test]\n",
    "    gp_train=pd.concat(gp_train,sort=False)\n",
    "    gp_test=pd.concat(gp_test,sort=False)\n",
    "    y_train,y_test=gp_train['label'].astype(int),gp_test['label'].astype(int)\n",
    "    x_train,x_test=gp_train.drop(['label'],axis=1),gp_test.drop(['label'],axis=1)\n",
    "    cls=SVC(kernel='linear')\n",
    "    cls.fit(x_train,y_train)\n",
    "    y_pred_train=cls.predict(x_train)\n",
    "    y_pred_test=cls.predict(x_test)\n",
    "    prob_pred_test=cls.decision_function(x_test)\n",
    "    acc_train.append(acc(y_train,y_pred_train))\n",
    "    acc_test.append(acc(y_test,y_pred_test))\n",
    "    \n",
    "    #full_match\n",
    "    prob_first=np.max(prob_pred_test,axis=1)\n",
    "    prob_second=np.median(prob_pred_test,axis=1)\n",
    "    prob=prob_first/prob_second\n",
    "    sel=prob>np.median(prob)\n",
    "    y_test_sel=y_test[sel]\n",
    "    y_pred_test_sel=y_test[sel]\n",
    "    x_test_sel=x_test[sel]\n",
    "    bingo=y_test.values==y_pred_test\n",
    "    fm=[]\n",
    "    for i in range(len(y_test_sel)):\n",
    "        if not bingo[i]:\n",
    "            fm.append(-1)\n",
    "        else:\n",
    "            if y_pred_test_sel[i]==1: fm.append(x_test_sel.iloc[i]['Fulltime Result_h'])\n",
    "            if y_pred_test_sel[i]==0: fm.append(x_test_sel.iloc[i]['Fulltime Result_d'])\n",
    "            if y_pred_test_sel[i]==-1:fm.append(x_test_sel.iloc[i]['Fulltime Result_a'])\n",
    "    fullmatch.append(np.mean(fm))\n",
    "    \n",
    "    \n",
    "print('acc_train:%s'%acc_train)\n",
    "print('mean:%f'%np.mean(acc_train))\n",
    "print('acc_test:%s'%acc_test)\n",
    "print('mean:%f'%np.mean(acc_test))\n",
    "print('fullmatch:%s'%fullmatch)\n",
    "print('mean:%f'%np.mean(fullmatch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_train,gp_test=train_test_split(gp_final)\n",
    "gp_train=pd.concat(gp_train,sort=False)\n",
    "gp_test=pd.concat(gp_test,sort=False)\n",
    "y_train,y_test=gp_train['label'].astype(int),gp_test['label'].astype(int)\n",
    "x_train,x_test=gp_train.drop(['label'],axis=1),gp_test.drop(['label'],axis=1)\n",
    "odds_train,odds_test=x_train[['Fulltime Result_h','Fulltime Result_d','Fulltime Result_a']],x_test[['Fulltime Result_h','Fulltime Result_d','Fulltime Result_a']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    net=slim.fully_connected(x,5)\n",
    "    net=slim.fully_connected(x,3)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(y_pred,y_true,odds):\n",
    "    y_pred_max=tf.reduce_max(y_pred,axis=1,keep_dims=True)\n",
    "    y_pred=tf.where(\n",
    "        tf.equal(y_pred_max, y_pred), \n",
    "        tf.constant(1, shape=y_pred.shape), \n",
    "        tf.constant(0, shape=y_pred.shape)\n",
    "    )\n",
    "    mask=tf.equal(y_pred,y_true)\n",
    "    earns=tf.where(mask,odds,-1)\n",
    "    return tf.reduce_mean(earns)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train.values.astype(np.float32), y_train.values.astype(np.float32), odds_train.values.astype(np.float32)))\n",
    "dataset = dataset.shuffle(50).repeat().batch(10)\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "x,y,odds=iter.get_next()\n",
    "\n",
    "with slim.arg_scope([slim.fully_connected],normalizer_fn=slim.batch_norm):\n",
    "    output=model(x)\n",
    "\n",
    "loss=get_loss(output,y,odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
